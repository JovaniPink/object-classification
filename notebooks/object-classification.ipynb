{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/notebooks/welcome.ipynb#scrollTo=P-H6Lw1vyNNd\n",
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the dependencies.\n",
    "import matplotlib.pyplot as plt # Dataset visualization.\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "# print(tensorflow.__version__)\n",
    "\n",
    "# from config import IFNEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-12f7fc1ee383>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/resources/test-image.jpeg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_conf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_common_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"yolov3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# It prints the detected objects’ labels and bounding boxes at the end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\cvlib\\object_detection.py\u001b[0m in \u001b[0;36mdetect_common_objects\u001b[1;34m(image, confidence, nms_thresh, model, enable_gpu)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdetect_common_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'yolov3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mHeight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.00392\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Look into this\n",
    "#https://www.tensorflow.org/hub/tutorials/tf2_image_retraining <---\n",
    "\n",
    "# cvlib it’s a high level library that runs object detection with just a few lines of code; it uses OpenCV and TensorFlow under the hood. We don’t even need to train a model our-self: cvlib uses a model pre-trained on the COCO dataset, capable of detecting 80 common objects. Which is totally sweet!\n",
    "\n",
    "# I'm going to load the cvlib library and the YOLOv3 model, then detect the objects present in the test-image.jpeg image.\n",
    "\n",
    "image = cv2.imread(\"../resources/test-image.jpeg\")\n",
    "boxes, labels, _conf = cv.detect_common_objects(image, model=\"yolov3\")\n",
    "\n",
    "# It prints the detected objects’ labels and bounding boxes at the end.\n",
    "print(labels, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to time things to figure out what is taking so long!\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "boxes, labels, _conf = cv.detect_common_objects(img, model=\"yolov3\")\n",
    "print(\"first detection: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I know I will be sending binary data representing the image or frame of a video stream, so I just can't use the cvlib with image files but raw binary image data. So I need to be able to read that data from the CLI or WEB FRAMEWORK\n",
    "\n",
    "# https://docs.python.org/3/library/sys.html but check this out https://docs.python.org/3/library/os.html#os.fdopen\n",
    "import sys\n",
    "\n",
    "\n",
    "# stdin stands for standard input which is a stream from which the program read its input data.\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    # expecting line in for of \"num,num\\n\" so we want to strip whitespaces and newlines.\n",
    "    line = line.strip()\n",
    "    # EOF\n",
    "    if line == \"\": break\n",
    "    \n",
    "    # convert string elements into integers and then sum them.\n",
    "    values = line.split(\",\")\n",
    "    nums = map(int, values)\n",
    "    result = sum(nums)\n",
    "\n",
    "    # send the result via stdout and back out as a string.\n",
    "    sys.stdout.write(str(result) + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # this is important becasue I see myself using Celery with RabbitMQ to handle all the incoming requests. https://docs.celeryproject.org/en/stable/getting-started/introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future work ...\n",
    "# def read_msg ...\n",
    "# def detect ...\n",
    "# def write_result ...\n",
    "\n",
    "# Since I'm dealing with sending binary data I could attach an ID to the string to note which image is coming from where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the result into a json string and we write to output_f the message’s total size total_msg_size\n",
    "from struct import unpack, pack\n",
    "\n",
    "def write_result(output, image_id, shape, boxes, labels):\n",
    "    result = json.dumps({\n",
    "        'shape': shape,\n",
    "        'boxes': boxes, \n",
    "        'labels': labels\n",
    "    }).encode(\"ascii\")\n",
    "\n",
    "    # Use a preappended uuid to the image string to indentify\n",
    "    total_msg_size = len(result) + UUID4_SIZE\n",
    "\n",
    "    header = pack(\"!I\", total_msg_size)\n",
    "    output.write(header)\n",
    "    output.write(image_id)\n",
    "    output.write(result)\n",
    "    output.flush()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}